<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>runAll_v2</name>
    <description/>
    <extended_description/>
    <job_version/>
  <directory>&#x2f;</directory>
  <created_user>-</created_user>
  <created_date>2015&#x2f;01&#x2f;08 11&#x3a;54&#x3a;00.176</created_date>
  <modified_user>-</modified_user>
  <modified_date>2015&#x2f;01&#x2f;08 11&#x3a;54&#x3a;00.176</modified_date>
    <parameters>
    </parameters>
    <slaveservers>
         <slaveserver><name>aaaa - bad-hdp22unsec-cent-n1.pentaho.dmz&#x3a;55557</name><hostname>bad-hdp22unsec-cent-n1.pentaho.dmz</hostname><port>55557</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp22unsec-cent-n3.pentaho.dmz&#x3a;55556</name><hostname>bad-hdp22unsec-cent-n3.pentaho.dmz</hostname><port>55556</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>pentaho-di</name><hostname>localhost</hostname><port>9080</port><webAppName>pentaho-di</webAppName><username>admin</username><password>Encrypted 2be98afc86aa7f2e4bb18bd63c99dbdde</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - sandbox.hortonworks.com&#x3a;55558</name><hostname>sandbox.hortonworks.com</hostname><port>55558</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - sandbox.hortonworks.com&#x3a;55557</name><hostname>sandbox.hortonworks.com</hostname><port>55557</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>Master</name><hostname>localhost</hostname><port>9997</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>DI</name><hostname>localhost</hostname><port>9081</port><webAppName>pentaho-di</webAppName><username>admin</username><password>Encrypted 2be98afc86aa7f2e4bb18bd63c99dbdde</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>winlocal</name><hostname>192.168.56.1</hostname><port>9999</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>DI4.8.3.4</name><hostname>localhost</hostname><port>9082</port><webAppName>pentaho-di</webAppName><username>joe</username><password>Encrypted 2be98afc86aa7f2e4bb18bd63c99dbdde</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - sandbox.hortonworks.com&#x3a;55556</name><hostname>sandbox.hortonworks.com</hostname><port>55556</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>Slave2</name><hostname>localhost</hostname><port>9999</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>Slave1</name><hostname>localhost</hostname><port>9998</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>10000</name><hostname>localhost</hostname><port>10000</port><webAppName/><username>cluster</username><password>Encrypted 2be98afc86aa7f2e4cb1aa265cd86aac8</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-mn.pentaho.com&#x3a;55557</name><hostname>bad-hdp21sec-cent-mn.pentaho.com</hostname><port>55557</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-jt.pentaho.com&#x3a;55556</name><hostname>bad-hdp21sec-cent-jt.pentaho.com</hostname><port>55556</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp22unsec-cent-n5.pentaho.dmz&#x3a;55557</name><hostname>bad-hdp22unsec-cent-n5.pentaho.dmz</hostname><port>55557</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-sl2.pentaho.com&#x3a;55557</name><hostname>bad-hdp21sec-cent-sl2.pentaho.com</hostname><port>55557</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-nn.pentaho.com&#x3a;55556</name><hostname>bad-hdp21sec-cent-nn.pentaho.com</hostname><port>55556</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-nn.pentaho.com&#x3a;55557</name><hostname>bad-hdp21sec-cent-nn.pentaho.com</hostname><port>55557</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-mn.pentaho.com&#x3a;55556</name><hostname>bad-hdp21sec-cent-mn.pentaho.com</hostname><port>55556</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-sl1.pentaho.com&#x3a;55558</name><hostname>bad-hdp21sec-cent-sl1.pentaho.com</hostname><port>55558</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>di_server</name><hostname>localhost</hostname><port>9080</port><webAppName>pentaho-di</webAppName><username>admin</username><password>Encrypted 2be98afc86aa7f2e4bb18bd63c99dbdde</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa &#x3a;55556</name><hostname>EPBYMINW3556T11</hostname><port>55556</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-sl1.pentaho.com&#x3a;55556</name><hostname>bad-hdp21sec-cent-sl1.pentaho.com</hostname><port>55556</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>Y</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - bad-hdp21sec-cent-nn.pentaho.com&#x3a;55558</name><hostname>bad-hdp21sec-cent-nn.pentaho.com</hostname><port>55558</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa - EPBYMINW3556T11&#x3a;55558</name><hostname>EPBYMINW3556T11</hostname><port>55558</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa</name><hostname>EPBYMINW3556T11</hostname><port>55557</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
         <slaveserver><name>aaaa &#x3a;55558</name><hostname>EPBYMINW3556T11</hostname><port>55558</port><webAppName/><username>bpass</username><password>Encrypted 2be98afc86aa7f2e4cb79ce72ce93bcc9</password><proxy_hostname/><proxy_port/><non_proxy_hosts/><master>N</master><sslMode>N</sslMode></slaveserver>
    </slaveservers>
<job-log-table><connection/>
<schema/>
<table/>
<size_limit_lines/>
<interval/>
<timeout_days/>
<field><id>ID_JOB</id><enabled>Y</enabled><name>ID_JOB</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>JOBNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>START_JOB_ENTRY</id><enabled>N</enabled><name>START_JOB_ENTRY</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></job-log-table>
<jobentry-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>JOBENTRYNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>RESULT</id><enabled>Y</enabled><name>RESULT</name></field><field><id>NR_RESULT_ROWS</id><enabled>Y</enabled><name>NR_RESULT_ROWS</name></field><field><id>NR_RESULT_FILES</id><enabled>Y</enabled><name>NR_RESULT_FILES</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field><field><id>COPY_NR</id><enabled>N</enabled><name>COPY_NR</name></field></jobentry-log-table>
<channel-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<checkpoint-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<max_nr_retries/>
<run_retry_period/>
<namespace_parameter/>
<save_parameters>Y</save_parameters>
<save_result_rows>Y</save_result_rows>
<save_result_files>Y</save_result_files>
<field><id>ID_JOB_RUN</id><enabled>Y</enabled><name>ID_JOB_RUN</name></field><field><id>ID_JOB</id><enabled>Y</enabled><name>ID_JOB</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>JOBNAME</name></field><field><id>NAMESPACE</id><enabled>Y</enabled><name>NAMESPACE</name></field><field><id>CHECKPOINT_NAME</id><enabled>Y</enabled><name>CHECKPOINT_NAME</name></field><field><id>CHECKPOINT_COPYNR</id><enabled>Y</enabled><name>CHECKPOINT_COPYNR</name></field><field><id>ATTEMPT_NR</id><enabled>Y</enabled><name>ATTEMPT_NR</name></field><field><id>JOB_RUN_START_DATE</id><enabled>Y</enabled><name>JOB_RUN_START_DATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>RESULT_XML</id><enabled>Y</enabled><name>RESULT_XML</name></field><field><id>PARAMETER_XML</id><enabled>Y</enabled><name>PARAMETER_XML</name></field></checkpoint-log-table>
   <pass_batchid>N</pass_batchid>
   <shared_objects_file/>
  <entries>
    <entry>
      <name>START</name>
      <description/>
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>41</xloc>
      <yloc>34</yloc>
      </entry>
    <entry>
      <name>LoadHDFSCopyFiles</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadHDFS&#x5c;LoadHDFSCopyFiles.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>240</xloc>
      <yloc>0</yloc>
      </entry>
    <entry>
      <name>LoadHDFSHadoopCopyFiles</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadHDFS&#x5c;LoadHDFSHadoopCopyFiles.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>0</yloc>
      </entry>
    <entry>
      <name>LoadHbase</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadHbase&#x5c;LoadHbase.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>613</xloc>
      <yloc>34</yloc>
      </entry>
    <entry>
      <name>HadoopJobExecutor</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;HadoopJobExecutor&#x5c;HadoopJobExecutor.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>64</xloc>
      <yloc>115</yloc>
      </entry>
    <entry>
      <name>Hadoop_Job_executor_MR2</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;HadoopJobExecutorMR2&#x5c;Hadoop_Job_executor_MR2.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>236</xloc>
      <yloc>116</yloc>
      </entry>
    <entry>
      <name>PDI_HBASE_IO_Smoketest</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;HBaseInputOutputSmoketest&#x5c;PDI_HBASE_IO_Smoketest.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>380</xloc>
      <yloc>100</yloc>
      </entry>
    <entry>
      <name>LoadHive</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadHive&#x5c;LoadHive.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>116</yloc>
      </entry>
    <entry>
      <name>OozieMapReduce</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;Oozie&#x5c;OozieMapReduce.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>619</xloc>
      <yloc>110</yloc>
      </entry>
    <entry>
      <name>PDI_Hadoop_IO_Smoketest</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;PDI_HadoopSmoketest&#x5c;PDI_Hadoop_IO_Smoketest.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>82</xloc>
      <yloc>192</yloc>
      </entry>
    <entry>
      <name>aggregate_mr</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce_Aggregate&#x24;&#x7b;file.separator&#x7d;aggregate_mr.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>230</xloc>
      <yloc>182</yloc>
      </entry>
    <entry>
      <name>PentahoMapReduce-Hadoop</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce_Hadoop&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce-Hadoop.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>335</xloc>
      <yloc>200</yloc>
      </entry>
    <entry>
      <name>PentahoMapReduce-HBase</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce_Hbase&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce-HBase.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>485</xloc>
      <yloc>180</yloc>
      </entry>
    <entry>
      <name>PentahoMapReduce-Hive</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce_Hive&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce-Hive.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>617</xloc>
      <yloc>196</yloc>
      </entry>
    <entry>
      <name>aggregate_pig</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;PigScriptExecutor&#x5c;aggregate_pig.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>69</xloc>
      <yloc>269</yloc>
      </entry>
    <entry>
      <name>SqoopExportHDFSTest</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;Sqoop&#x5c;SqoopExportHDFSTest.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>204</xloc>
      <yloc>273</yloc>
      </entry>
    <entry>
      <name>SqoopImportHBaseTest</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;SqoopImport_HBase&#x5c;SqoopImportHBaseTest.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>477</xloc>
      <yloc>254</yloc>
      </entry>
    <entry>
      <name>SqoopImportHiveTest</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;SqoopImport_Hive&#x5c;SqoopImportHiveTest.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>618</xloc>
      <yloc>275</yloc>
      </entry>
    <entry>
      <name>YARN-Kettle-test</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;YarnCarte&#x5c;YARN-Kettle-test.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>60</xloc>
      <yloc>359</yloc>
      </entry>
    <entry>
      <name>Success</name>
      <description/>
      <type>SUCCESS</type>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>200</xloc>
      <yloc>358</yloc>
      </entry>
    <entry>
      <name>Set variables</name>
      <description/>
      <type>SET_VARIABLES</type>
      <replacevars>Y</replacevars>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x2f;test.properties</filename>
      <file_variable_type>JVM</file_variable_type>
      <fields>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>128</xloc>
      <yloc>35</yloc>
      </entry>
    <entry>
      <name>LoadHiveTableOutput &#x28;for hive .14&#x29;</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;&#x5c;LoadHiveOutput&#x5c;LoadHiveTableOutput.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>432</yloc>
      </entry>
    <entry>
      <name>SqoopImportHDFS</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;SqoopImport_HDFS&#x5c;SqoopImportHDFSTest.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>357</xloc>
      <yloc>273</yloc>
      </entry>
    <entry>
      <name>LoadImpala</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadImpala&#x5c;LoadImpala.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>272</xloc>
      <yloc>432</yloc>
      </entry>
    <entry>
      <name>LoadImpalaOutput</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadImpalaOutput&#x5c;LoadImpalaTableOutput.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>528</xloc>
      <yloc>432</yloc>
      </entry>
    <entry>
      <name>MapReduce-Impala</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;PentahoMapReduce_Impala&#x5c;PentahoMapReduce-Impala.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>384</xloc>
      <yloc>432</yloc>
      </entry>
    <entry>
      <name>LoadHiveNondefault</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadHiveNondefault&#x5c;LoadHiveNondefault.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>496</yloc>
      </entry>
    <entry>
      <name>LoadImpalaNondefault</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;LoadImpalaNondefault&#x5c;LoadImpalaNondefault.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>272</xloc>
      <yloc>496</yloc>
      </entry>
    <entry>
      <name>Spark submit Pi</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;SparkSubmitPi&#x5c;spark_submit_pi.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>432</xloc>
      <yloc>496</yloc>
      </entry>
    <entry>
      <name>Spark Submit Wordcount</name>
      <description/>
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id/>
      <filename>&#x24;&#x7b;SHIMS_DATA&#x7d;&#x24;&#x7b;file.separator&#x7d;SparkSubmitWordcount&#x5c;spark_submit_wordcount.kjb</filename>
      <jobname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name/>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>592</xloc>
      <yloc>496</yloc>
      </entry>
  </entries>
  <hops>
    <hop>
      <from>LoadHDFSCopyFiles</from>
      <to>LoadHDFSHadoopCopyFiles</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>LoadHDFSHadoopCopyFiles</from>
      <to>LoadHbase</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>LoadHbase</from>
      <to>HadoopJobExecutor</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>HadoopJobExecutor</from>
      <to>Hadoop_Job_executor_MR2</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Hadoop_Job_executor_MR2</from>
      <to>PDI_HBASE_IO_Smoketest</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>PDI_HBASE_IO_Smoketest</from>
      <to>LoadHive</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>LoadHive</from>
      <to>OozieMapReduce</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>OozieMapReduce</from>
      <to>PDI_Hadoop_IO_Smoketest</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>PDI_Hadoop_IO_Smoketest</from>
      <to>aggregate_mr</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>aggregate_mr</from>
      <to>PentahoMapReduce-Hadoop</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>PentahoMapReduce-Hadoop</from>
      <to>PentahoMapReduce-HBase</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>PentahoMapReduce-HBase</from>
      <to>PentahoMapReduce-Hive</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>PentahoMapReduce-Hive</from>
      <to>aggregate_pig</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>aggregate_pig</from>
      <to>SqoopExportHDFSTest</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHBaseTest</from>
      <to>SqoopImportHiveTest</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHiveTest</from>
      <to>YARN-Kettle-test</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>YARN-Kettle-test</from>
      <to>Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>START</from>
      <to>Set variables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Set variables</from>
      <to>LoadHDFSCopyFiles</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>SqoopExportHDFSTest</from>
      <to>SqoopImportHDFS</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>SqoopImportHDFS</from>
      <to>SqoopImportHBaseTest</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Set variables</from>
      <to>LoadHbase</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>N</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>Please add &#x22;SHIMS_DATA&#x22; variable to kettle.properties and set a valid value to it &#xd;&#xa;&#x28;Example&#x3a; &#x22;file&#x3a;&#x2f;&#x2f;&#x2f;D&#x3a;&#x5c;hadoop-shims-automation&#x22;&#x29;&#xd;&#xa;&#xd;&#xa;copy file &#x22;cluster.xml&#x22; to &#x22;...&#x5c;.pentaho&#x5c;metastore&#x5c;pentaho&#x5c;NamedCluster&#x22; folder&#xd;&#xa;&#x28;Thanks to a new &#x201c;Named Claster&#x201d; functionality. Notice, that you need &#x201c;.type.xml&#x201d; file at the same folder, it is created automatically when any named cluster is created&#x29;.&#xd;&#xa;&#xd;&#xa;Please open test.properties and set all variables for your environment&#xd;&#xa;&#xd;&#xa;&#x22;LoadHDFSCopyFiles&#x22;, &#x22;LoadHDFSHadoopCopyFiles&#x22;, &#x22;LoadHbase&#x22; &#xd;&#xa;is a preparation jobs and have to be runed before other jobs. &#xd;&#xa;&#xd;&#xa;If &#x27;useChmod777&#x27; variable is set to &#x27;false&#x27; next commands should be executed manually&#x3a;&#xd;&#xa;&#xd;&#xa;hadoop fs -chmod -R 777 &#x2f;user&#x2f;devuser&#xd;&#xa;&#xd;&#xa;echo &#x22;create &#x27;weblogs&#x27;, &#x27;pageviews&#x27;&#x22; &#x7c; hbase shell&#xd;&#xa;echo &#x22;create &#x27;weblogs2&#x27;, &#x27;pageviews2&#x27;&#x22; &#x7c; hbase shell&#xd;&#xa;echo &#x22;create &#x27;hbasesqooptest2&#x27;, &#x27;pageviews&#x27;&#x22; &#x7c; hbase shell</note>
      <xloc>876</xloc>
      <yloc>7</yloc>
      <width>1113</width>
      <heigth>370</heigth>
      <fontname>Segoe UI</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>

</job>
